# @package _global_
defaults:
  - override /data: depth_estimation/scannetpp_hypersim_v3
  - override /model@model: depth_estimation/depth_anything
  - override /callbacks: 
    - model_checkpoint_simple
    - train_speed_timer

pl_trainer:
  precision: 32
  limit_train_batches: 1000
  limit_val_batches: 100
  max_epochs: 200
  log_every_n_steps: 50
  accumulate_grad_batches: 1 # * 8 if use only one gpu
  strategy: ddp_find_unused_parameters_true
  devices: 8

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ${output_dir} # /save_dir/name/version/sub_dir
  name: ""
  version: "tb" # merge name and version

task: depth_estimation
exp_name: june_depthanythingmetric_scannetpp_perscene_hypersim

# data:
#   loader_opts:
#     train:
#       - batch_size: 2
#         num_workers: 4
#       - batch_size: 2
#         num_workers: 4
model:
  pipeline:
    _target_: lib.model.depth_estimation.depth_anything.depth_anything_upsample_fusion.DepthAnythingPipeline
    range_ratio: [1., 0., 0.] # 8x, 192x256, 8x--192x256
    block_type: 'featurefusiondepthblock'
    load_pretrain_backbone: null
    load_pretrain_net: ${oc.env:workspace}/cache_models/depth_anything/checkpoints/v2_model_metric_ftlht.ckpt
    normalize_disp_type: minmax
    loss_cfg:
      _target_: lib.model.depth_estimation.depth_anything.loss.L1loss_Gradient_upsample
      gradient_weight: 0.5

# callbacks:
#   model_checkpoint:
#     _target_: pytorch_lightning.callbacks.ModelCheckpoint
#     dirpath: ${output_dir}/checkpoints/
#     filename: "e{epoch:03d}-s{step:06d}"
#     save_last: null # additionally always save an exact copy of the last checkpoint to a file last.ckpt
#     save_top_k: 1 # save k best models (determined by above metric)
#     auto_insert_metric_name: False # when True, the checkpoints filenames will contain the metric name
#     save_weights_only: True # if True, then only the modelâ€™s weights will be saved
#     every_n_train_steps: null # number of training steps between checkpoints
#     every_n_epochs: 50 # number of epochs between checkpoints
data:
  train_dataset:
    dataset_opts: 
      - _target_: lib.dataset.depth_estimation.hypersim_v3.Dataset
        data_root: ${oc.env:workspace}/hypersim
        rgb_dir: ${oc.env:workspace}/datasets/HyperSim
        dpt_dir: ${oc.env:workspace}/processed_datasets/HyperSim
        split_path: ${oc.env:workspace}/processed_datasets/HyperSim/metadata_valid_0.05_splits_ht.json
        split: 'train'
        width: 1008
        height: 756
        resize_target: True
        ensure_multiple_of: 14
      - _target_: lib.dataset.depth_estimation.scannetpp_v3.Dataset
        split_path: '/mnt/bn/haotongdata/Datasets/scannetpp/splits/test_meta_data.json'
        scene: 5f99900f09
        split: 'train'
        width: 1008
        height: 756
        resize_target: True
        ensure_multiple_of: 14
    loader_opts: 
      - batch_size: 1
      - batch_size: 2
  val_dataset:
    dataset_opts:
      _target_: lib.dataset.depth_estimation.scannetpp_v3.Dataset
      split_path: '/mnt/bn/haotongdata/Datasets/scannetpp/splits/test_meta_data.json'
      split: 'val'
      width: 1008
      scene: 5f99900f09
      height: 756
      resize_target: True
      frames: [0, -1, 25]
      ensure_multiple_of: 14