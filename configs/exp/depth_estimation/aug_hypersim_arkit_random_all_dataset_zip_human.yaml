# @package _global_
defaults:
  - override /data: depth_estimation/hypersim_arkit
  - override /model@model: depth_estimation/depth_anything
  - override /callbacks: 
    - model_checkpoint_simple
    - train_speed_timer

pl_trainer:
  precision: 32
  limit_train_batches: 1000
  limit_val_batches: 100
  max_epochs: 200
  log_every_n_steps: 50
  accumulate_grad_batches: 1 # * 8 if use only one gpu
  strategy: ddp_find_unused_parameters_true
  devices: 8

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ${output_dir} # /save_dir/name/version/sub_dir
  name: ""
  version: "tb" # merge name and version

task: depth_estimation
exp_name: aug_hypersim_arkit_random_all_dataset_zip_human

model:
  pipeline:
    _target_: lib.model.depth_estimation.depth_anything.depth_anything_upsample_fusion.DepthAnythingPipeline
    range_ratio: [1., 0., 0.] # 8x, 192x256, 8x--192x256
    block_type: 'featurefusiondepthblock'
    # encoder: 'vits'
    # features: 64
    # out_channels: [48, 96, 192, 384]
    load_pretrain_backbone: null
    load_pretrain_net: ${oc.env:workspace}/cache_models/depth_anything/checkpoints/v2_model_metric_ftlht.ckpt
    normalize_disp_type: minmax
    add_grad: False
    # grad_tags: ['HyperSim']
    grad_tags: ['HyperSim', 'scannetpp']
    scannetpp_grad_weight: 0.5
    loss_cfg:
      # _target_: lib.model.depth_estimation.depth_anything.loss.L1loss_Gradient_upsample
      _target_: lib.model.depth_estimation.depth_anything.loss.L1loss_Gradient_meshdepth_zip
      gradient_weight: 2.
    warp_func:
      _target_: lib.model.depth_estimation.depth_anything.depth_warp.WarpMinMax

data:
  _target_: lib.datamodule.general_datamodule_v3.GeneralDataModule
  train_dataset:
    dataset_opts: 
      - _target_: lib.dataset.depth_estimation.hypersim_v3.Dataset
        data_root: ${oc.env:workspace}/hypersim
        rgb_dir: ${oc.env:workspace}/datasets/HyperSim
        dpt_dir: ${oc.env:workspace}/processed_datasets/HyperSim
        split_path: ${oc.env:workspace}/processed_datasets/HyperSim/metadata_valid_0.05_splits_ht.json
        split: 'train'
        transforms:
          - _target_: lib.dataset.depth_estimation.transform.Resize
            ensure_multiple_of: 14
            width: 1008
            height: 756
            resize_target: True
          - _target_: lib.dataset.depth_estimation.transform.PrepareForNet
          - _target_: lib.dataset.depth_estimation.transform.SimLowRes
            height: 192
            width: 256
            interpolation: 'random_simu'
      - _target_: lib.dataset.depth_estimation.hypersim_v3.Dataset
        data_root: ${oc.env:workspace}/hypersim
        rgb_dir: ${oc.env:workspace}/datasets/HyperSim
        dpt_dir: ${oc.env:workspace}/processed_datasets/HyperSim
        split_path: ${oc.env:workspace}/processed_datasets/HyperSim/metadata_valid_0.05_splits_ht.json
        split: 'train'
        transforms:
          - _target_: lib.dataset.depth_estimation.transform.PrepareForNet
          - _target_: lib.dataset.depth_estimation.transform.Crop
            size: 630
          - _target_: lib.dataset.depth_estimation.transform.SimLowRes
            ranges: [84, 160]
            range_prob: [0.2, 0.4, 0.4]
            interpolation: 'random_simu'
      - _target_: lib.dataset.depth_estimation.scannetpp_v3.Dataset
        # split_path: '/mnt/bn/haotongdata/Datasets/scannetpp/splits/train_meta_data_meshdepth_0614.json'
        split_path: '/mnt/bn/haotongdata/Datasets/scannetpp/splits/train_meta_data_zipdepth_meshdepth_sem_0614.json'
        split: 'train'
        transforms:
          - _target_: lib.dataset.depth_estimation.transform.Resize
            ensure_multiple_of: 14
            width: 1008
            height: 756
            resize_target: True
          - _target_: lib.dataset.depth_estimation.transform.PrepareForNet
      - _target_: lib.dataset.depth_estimation.arkitscenes_v3.Dataset
        data_root: ${oc.env:workspace}/datasets/ARKitScenes/download/upsampling
        meta_file: ${oc.env:workspace}/datasets/ARKitScenes/download/upsampling/metadata.csv
        split_file: /mnt/bn/haotongdata/home/linhaotong/workspaces/pl_htcode/processed_datasets/ARKitScenes/train.txt
        split: 'train'
        frames: [0, -1, 1]
        transforms:
          - _target_: lib.dataset.depth_estimation.transform.Resize
            ensure_multiple_of: 14
            width: 1008
            height: 756
            resize_target: True
          - _target_: lib.dataset.depth_estimation.transform.Rotate
          - _target_: lib.dataset.depth_estimation.transform.PrepareForNet
      - _target_: lib.dataset.depth_estimation.human_gps_render.Dataset
        split_file: data/pl_htcode/processed_datasets/human_gps_render/train.json
        split: 'train'
        frames: [0, -1, 1]
        normalize_depth: False
        all_valid: True
        transforms:
          - _target_: lib.dataset.depth_estimation.transform.PrepareForNet
          - _target_: lib.dataset.depth_estimation.transform.Crop
            size: [134, 8, 890, 1016] # centercrop
          - _target_: lib.dataset.depth_estimation.transform.SimLowRes
            height: 192
            width: 256
            interpolation: 'random_simu'
  val_dataset:
    dataset_opts:
      _target_: lib.dataset.depth_estimation.arkitscenes_v3.Dataset
      data_root: ${oc.env:workspace}/datasets/ARKitScenes/download/upsampling
      meta_file: ${oc.env:workspace}/datasets/ARKitScenes/download/upsampling/metadata.csv
      split_file: /mnt/bn/haotongdata/home/linhaotong/workspaces/pl_htcode/processed_datasets/ARKitScenes/val.txt
      split: 'val'
      frames: [0, -1, 20]
      transforms:
        - _target_: lib.dataset.depth_estimation.transform.Resize
          ensure_multiple_of: 14
          width: 1008
          height: 756
          resize_target: True
        - _target_: lib.dataset.depth_estimation.transform.Rotate
        - _target_: lib.dataset.depth_estimation.transform.PrepareForNet