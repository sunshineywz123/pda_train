# @package _global_
defaults:
  - override /data: depth_estimation/arkitscenes_transform
  - override /model@model: depth_estimation/mspf
  - override /callbacks: 
    - model_checkpoint_simple
    - train_speed_timer

pl_trainer:
  precision: 32
  limit_train_batches: 10000
  limit_val_batches: 100
  max_epochs: 100
  log_every_n_steps: 50
  accumulate_grad_batches: 1 # * 8 if use only one gpu
  # num_sanity_val_steps: -1
  # strategy: ddp_find_unused_parameters_true

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ${output_dir} # /save_dir/name/version/sub_dir
  name: ""
  version: "tb" # merge name and version

task: depth_estimation
exp_name: mspf

model:
  pipeline:
    # upsample_factor: 8
    pretrain_path: '/mnt/bn/haotongdata/Datasets/ARKitScenes/depth_upsampling/log/MSPF_x8/checkpoint_step-130000'
data:
  dataset_opts:
    train:
      train_crop_size: 512
      down_scale: 8
    val:
      ensure_multiple_of: 32
  loader_opts:
    train:
      batch_size: 16
      num_workers: 16