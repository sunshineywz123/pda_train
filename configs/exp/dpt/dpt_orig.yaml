# @package _global_
defaults:
  - override /data: dpt/hypersim_nonorm
  - override /model: dpt/dpt_depth
  - override /callbacks: 
    - model_checkpoint_simple
    - train_speed_timer
    # - lr_monitor

pl_trainer:
  precision: 16-mixed
  max_epochs: 100
  log_every_n_steps: 100
  accumulate_grad_batches: 8
  limit_train_batches: 10000

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ${output_dir} # /save_dir/name/version/sub_dir
  name: ""
  version: "tb" # merge name and version

task: dpt_depth
exp_name: dpt_orig