import os
import imageio
from os.path import join
import argparse
import sys
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

from lib.utils.parallel_utils import parallel_execution
sys.path.append('.')
import cv2
import open3d as o3d
import glob

def save_img(path, img):
    if len(img.shape) == 2:
        if img.dtype == np.float32 or img.dtype == np.float64:
            min_v, max_v = np.min(img), np.max(img)
            max_v = 80.
            img = (img - min_v) / max((max_v - min_v), 0.01)
            img = np.clip(img, 0., 1.)
            img = (img * 255).astype(np.uint8)
        elif img.dtype == np.bool_:
            img = img.astype(np.uint8) * 255
    print(img.dtype)
    imageio.imwrite(path, img)

def sample_lidar_lines(
    depth_map: np.ndarray, intrinsics: np.ndarray, reserve_ratio: float = 0.5, tar_lines: int = 64,
) -> np.ndarray:
    """
    Takes in input a depth map generated by a 64 line lidar and sparsify the number of
    lines used, returning a sparse depth map with less lidar lines.
    Parameters
    ----------
    depth_map: array like
        sparse depth map of shape H x W x 1
    intrinsics: array like
        the intrinsic parameters of shape 3 x 3
    keep_ratio: float, default 1.0
        the sparsification parameter, 1.0 is 64 lines, 0.50 roughly 32 lines and so on.
    Returns
    -------
    sparse_depth_map: array like
        the sparsified depth map of shape H x W x 1
    """
    v, u, _ = np.nonzero(depth_map)
    z = depth_map[v, u, 0]
    points = np.linalg.inv(intrinsics) @ (np.vstack([u, v, np.ones_like(u)]) * z)
    points = points.transpose([1, 0])

    scan_y = points[:, 1]
    distance = np.linalg.norm(points, 2, axis=1)
    pitch = np.arcsin(scan_y / distance)
    num_points = np.shape(pitch)[0]
    pitch = np.reshape(pitch, (num_points, 1))
    max_pitch = np.max(pitch)
    min_pitch = np.min(pitch)
    
    max_waymo_pitch = 0.29203
    min_waymo_pitch = -0.07361
    
    num_lines = int(420 * (min_waymo_pitch - max_pitch) / (min_pitch - max_pitch)) - 1
    # tar_lines = 64
    keep_ratio = tar_lines / num_lines
    
    angle_interval = (max_pitch - min_waymo_pitch) / num_lines
    angle_label = np.round((pitch - min_pitch) / angle_interval)
    sampling_mask = angle_label % int((1.0 / keep_ratio)) == 0
    sampling_mask = sampling_mask & (pitch >= min_waymo_pitch)

    final_mask = np.zeros_like(depth_map, dtype=bool)
    final_mask[depth_map[..., 0] > 0] = sampling_mask
    
    random_reserve = reserve_ratio
    random_mask = np.random.random(final_mask.shape) < random_reserve
    
    grid_mask = np.zeros_like(final_mask, dtype=bool)
    # grid_mask[::2] = True
    grid_mask[:, ::2] = True
    
    max_val = 80
    trunc_val = 50
    distance_drop = ((depth_map - trunc_val) / (max_val - trunc_val)) + np.random.random(depth_map.shape) 
    final_mask = final_mask & grid_mask & random_mask & (distance_drop < 1.)
    plt.imshow(final_mask[..., 0])
    plt.axis('off')
    plt.tight_layout()
    plt.savefig('test.jpg')
    plt.close()
    
    img = final_mask[..., 0].astype(np.uint8) * 255
    imageio.imwrite('lidar_msk.png', img)
    save_img('vis_crop_mask.png', final_mask.reshape(420, 630))
    import ipdb; ipdb.set_trace()
    sampled_depth = np.zeros_like(final_mask, dtype=np.float32)
    sampled_depth[final_mask] = depth_map[final_mask]
    return sampled_depth

def project_front_lidar(lidar_path, jpg_path=None, depth_path=None, output_path=None, translation=np.asarray([0.5, 0., 0.]), min_depth=3.):
    pcd = o3d.io.read_point_cloud(lidar_path)
    world_points = np.asarray(pcd.points)
    cam_points = world_points + translation[None]
    cam_points = cam_points[:, [1, 2, 0]]
    cam_points[:, 1] *= -1

    # img = cv2.imread(jpg_path)
    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # img_depth = cv2.imread(depth_path)
    # # depth = cv2.cvtColor(depth, cv2.COLOR_BGR2RGB)
    DEPTH_C = np.array(1000.0 / (256 * 256 * 256 - 1), np.float32)
    # depth = (img_depth[:, :, 0] * 256. * 256. + img_depth[:, :, 1] * 256. + img_depth[:, :, 2]) * DEPTH_C
    
    ixt = np.eye(3)
    height, width = 800, 1280
    ixt[0, 0], ixt[1, 1], ixt[0, 2], ixt[1, 2] = 640, 640, 640, 400
    
    # focal_x = focal_y = width / (2 * tan(FoV * np.pi / 360.0))
    
    img_points = cam_points @ ixt.T
    msk = img_points[:, 2] > 0.1
    img_points = img_points[msk]
    img_points[:, :2]= img_points[:, :2] / img_points[:, 2:]
    msk = (img_points[:, 0] >= 0) & (img_points[:, 0] < width) & (img_points[:, 1] >= 0) & (img_points[:, 1] < height) & (img_points[:, 2] > min_depth)
    img_points = img_points[msk]
    x = img_points[:, 0].astype(int)
    y = img_points[:, 1].astype(int)
    
    
    output_depth = np.zeros((height, width), np.float32)
    output_img = np.zeros((height, width, 3), np.uint8)
    output_depth[y, x] = img_points[:, 2]
    # output_depth[y, x] = depth[y, x]
    output_depth = output_depth / DEPTH_C
    output_img[..., 0] = (output_depth // (256 * 256)).astype(np.uint8)
    output_img[..., 1] = ((output_depth % (256 * 256)) // 256).astype(np.uint8)
    output_img[..., 2] = (output_depth % (256 * 256 * 256)).astype(np.uint8)
    if output_path is None: output_path = lidar_path.replace('_center.ply', '_front.png').replace('/center/', '/front/')
    cv2.imwrite(output_path, output_img)
    # cv2.imwrite('test_gt_depth.png', output_img)
    # cv2.imwrite('gt_depth.png', img_depth)
    # import ipdb; ipdb.set_trace()
    # import ipdb; ipdb.set_trace()
    # depth_points = depth[y, x]
    # import matplotlib.pyplot as plt
    # plt.subplot(131)
    # sparse_depth = np.zeros_like(depth)
    # sparse_depth[y, x] = depth_points
    # sparse_depth = np.clip(sparse_depth / 150, 0, 1)
    # plt.imshow(sparse_depth)
    # # plt.plot(img_points[:, 0], img_points[:, 1], 'r.')
    # plt.axis('off')
    
    # pcd = o3d.geometry.PointCloud()
    # pcd.points = o3d.utility.Vector3dVector(cam_points[msk])
    
    # plt.subplot(132)
    # plt.imshow(img)
    # plt.axis('off')
    
    # plt.subplot(133)
    # plt.imshow(np.clip(depth / 150, 0, 1))
    # plt.tight_layout()
    # plt.savefig('test.jpg', dpi=300)
    # plt.axis('off')
    # import ipdb; ipdb.set_trace()
    
def vis_crop_item(item):
    image_path = item.replace('lidar_center.ply', 'img_front.jpg').replace('/center/', '/front/')   
    lidar_path = item.replace('lidar_center.ply', 'lidar_front.png').replace('/center/', '/front/')
    depth_path = item.replace('lidar_center.ply', 'depth_front.png').replace('/center/', '/front/')
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    lidar = cv2.imread(lidar_path)
    DEPTH_C = np.array(1000.0 / (256 * 256 * 256 - 1), np.float32)
    lidar_depth = (lidar[:, :, 0] * 256. * 256. + lidar[:, :, 1] * 256. + lidar[:, :, 2]) * DEPTH_C
    depth = cv2.imread(depth_path)
    # depth = cv2.cvtColor(depth, cv2.COLOR_BGR2RGB)
    depth = (depth[:, :, 0] * 256. * 256. + depth[:, :, 1] * 256. + depth[:, :, 2]) * DEPTH_C
    msk = lidar_depth != 0
    
    

            
    
    plt.subplot(231)
    plt.imshow(image)
    save_img('vis_orig_img.png', image)
    plt.axis('off')
    plt.subplot(232)
    plt.imshow(depth)
    save_img('vis_orig_depth.png', depth)
    plt.axis('off')
    plt.subplot(233)
    plt.imshow(msk)
    save_img('vis_orig_mask.png', msk)
    plt.axis('off')
    
    W, H = 1280, 800
    crop_w, crop_h = 630, 420
    top_w, top_h = (W - crop_w) // 2, (H - crop_h) // 2
    bot_w, bot_h = top_w + crop_w, top_h + crop_h
    image = image[top_h:bot_h, top_w:bot_w]
    depth = depth[top_h:bot_h, top_w:bot_w]
    msk = msk[top_h:bot_h, top_w:bot_w]
    lidar_depth = lidar_depth[top_h:bot_h, top_w:bot_w]
    plt.subplot(234)
    plt.imshow(image)
    save_img('vis_crop_img.png', image)
    plt.axis('off')
    plt.subplot(235)
    plt.imshow(depth)
    save_img('vis_crop_depth.png', depth)
    plt.axis('off')
    plt.subplot(236)
    fx, fy = 640, 640
    cx, cy = crop_w / 2., crop_h / 2.
    ixt = np.eye(3)
    ixt[0, 0], ixt[1, 1], ixt[0, 2], ixt[1, 2] = fx, fy, cx, cy
    # from lib.utils.geo_utils import depth2pcd, export_pcd 
    # pcd = depth2pcd(depth, ixt, depth_min=1, depth_max=80, color=None, ext=None, conf=None)
    # lidar_pcd = depth2pcd(lidar_depth, ixt, depth_min=1, depth_max=80, color=None, ext=None, conf=None)
    # export_pcd('depth.ply', pcd)
    # export_pcd('lidar.ply', lidar_pcd)
    sample_lidar_lines(depth[..., None], ixt, reserve_ratio=0.5, tar_lines=64)
    

def main(args):
    jpg_path = '/mnt/bn/haotongdata/home/linhaotong/projects/pl_htcode/data/pl_htcode/preview/haotongdata/Datasets/shift/discrete/images/val/front/0aee-69fd/00000000_img_front.jpg'
    depth_path = '/mnt/bn/haotongdata/home/linhaotong/projects/pl_htcode/data/pl_htcode/preview/haotongdata/Datasets/shift/discrete/images/val/front/0aee-69fd/00000000_depth_front.png'
    lidar_path = '/mnt/bn/haotongdata/home/linhaotong/projects/pl_htcode/data/pl_htcode/preview/haotongdata/Datasets/shift/discrete/images/val/center/0aee-69fd/00000000_lidar_center.ply'
    output_path = '/mnt/bn/haotongdata/home/linhaotong/projects/pl_htcode/data/pl_htcode/preview/haotongdata/Datasets/shift/discrete/images/val/front/0aee-69fd/00000000_lidar_front.png'
    # project_front_lidar(lidar_path, output_path=output_path)
    root_dir = '/mnt/bn/haotongdata/home/linhaotong/projects/pl_htcode/data/pl_htcode/preview/haotongdata/Datasets/shift/discrete/images'
    splits = ['train', 'val']
    metas = []
    for split in tqdm(splits):
        scenes = os.listdir(join(root_dir, split, 'front'))
        for scene in tqdm(scenes[:10]):
            imgs = glob.glob(join(root_dir, split, 'front', scene, '*_img_front.jpg'))
            lidars = glob.glob(join(root_dir, split, 'center', scene, '*_lidar_center.ply'))
            assert len(imgs) == len(lidars), f'{scene} {len(imgs)} {len(lidars)}'
            metas.extend(lidars[::100])
    for meta in tqdm(metas):
        vis_crop_item(meta)
    # parallel_execution(metas, 
    #                    action=project_front_lidar,
    #                    num_processes=32,
    #                    print_progress=True)

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', type=str, default='/mnt/bn/haotongdata/Datasets/DyDToF')
    parser.add_argument('--output', type=str)
    args = parser.parse_args()
    return args

if __name__ == '__main__':
    args = parse_args()
    main(args)